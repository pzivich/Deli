{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfacf929",
   "metadata": {},
   "source": [
    "# Chapter 7: M-Estimation (Estimating Equations)\n",
    "From Boos DD, & Stefanski LA. (2013). M-estimation (estimating equations). In Essential Statistical Inference (pp. 297-337). Springer, New York, NY.\n",
    "\n",
    "Examples of M-Estimation provided in that chapter are replicated here using `delicatessen`. Reading the chapter and looking at the corresponding implementations is likely to be the best approach to learning both the theory and application of M-Estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3583f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version:        1.19.5\n",
      "SciPy version:        1.5.4\n",
      "Pandas version:       1.1.5\n",
      "Delicatessen version: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Initial setup\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import delicatessen\n",
    "from delicatessen import MEstimator\n",
    "\n",
    "np.random.seed(80950841)\n",
    "\n",
    "print(\"NumPy version:       \", np.__version__)\n",
    "print(\"SciPy version:       \", sp.__version__)\n",
    "print(\"Pandas version:      \", pd.__version__)\n",
    "print(\"Delicatessen version:\", delicatessen.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fbb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a generic data set for following examples\n",
    "n = 200\n",
    "data = pd.DataFrame()\n",
    "data['Y'] = np.random.normal(loc=10, scale=2, size=n)\n",
    "data['X'] = np.random.normal(loc=5, size=n)\n",
    "data['C'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2dd044",
   "metadata": {},
   "source": [
    "### 7.2.2 Sample Mean and Variance\n",
    "The first example is the estimating equations for the mean and variance. Here, estimating equations for both the mean and variance are stacked together:\n",
    "\n",
    "$$\\psi(Y_i, \\theta) = \n",
    "\\begin{bmatrix}\n",
    "    Y_i - \\theta_1\\\\\n",
    "    (Y_i - \\theta_1)^2 - \\theta_2\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "The top estimating equation is the mean, and the bottom estimating equation is the (asymptotic) variance. Here, both the by-hand and built-in estimating equations are demonstrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b3a029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Mean & Variance\n",
      "=========================================================\n",
      "M-Estimation: by-hand\n",
      "Theta: [10.16284625  4.11208477]\n",
      "Var:  \n",
      " [[ 4.11208409 -1.6740001 ]\n",
      " [-1.6740001  36.16386652]]\n",
      "---------------------------------------------------------\n",
      "Closed-Form\n",
      "Mean:  10.162846250198633\n",
      "Var:   4.112084770881207\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def psi_mean_var(theta):\n",
    "    \"\"\"By-hand stacked estimating equations\"\"\"\n",
    "    return (data['Y'] - theta[0],\n",
    "            (data['Y'] - theta[0])**2 - theta[1])\n",
    "\n",
    "\n",
    "\n",
    "estr = MEstimator(psi_mean_var, init=[0, 0])\n",
    "estr.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Mean & Variance\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation: by-hand\")\n",
    "print(\"Theta:\", estr.theta)\n",
    "print(\"Var:  \\n\", estr.asymptotic_variance)\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Closed-Form\")\n",
    "print(\"Mean: \", np.mean(data['Y']))\n",
    "print(\"Var:  \", np.var(data['Y'], ddof=0))\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275efcf8",
   "metadata": {},
   "source": [
    "Notice that $\\theta_2$ also matches the first element of the (asymptotic) variance matrix. These two values should match (since they are estimating the same thing). Further, as shown the closed-form solutions for the mean and variance are equal to the M-Estimation approach.\n",
    "\n",
    "The following uses the built-in estimating equation to estimate the mean and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e3c0818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Mean & Variance\n",
      "=========================================================\n",
      "M-Estimation: built-in\n",
      "Theta: [10.16284625  4.11208477]\n",
      "Var:  \n",
      " [[ 4.11208409 -1.6740001 ]\n",
      " [-1.6740001  36.16386652]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "from delicatessen.estimating_equations import ee_mean_variance\n",
    "\n",
    "def psi_mean_var_default(theta):\n",
    "    \"\"\"Built-in stacked estimating equations\"\"\"\n",
    "    return ee_mean_variance(y=np.asarray(data['Y']), theta=theta)\n",
    "\n",
    "\n",
    "estr = MEstimator(psi_mean_var_default, init=[0, 0])\n",
    "estr.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Mean & Variance\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation: built-in\")\n",
    "print(\"Theta:\", estr.theta)\n",
    "print(\"Var:  \\n\", estr.asymptotic_variance)\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c4fb6",
   "metadata": {},
   "source": [
    "### 7.2.3 Ratio Estimator\n",
    "The next example is a ratio estimator, which can be written as either a single estimating equation or as three stacked estimating equations. First is the single estimating equation version\n",
    "\n",
    "$$\\psi(Y_i, \\theta) = \n",
    "\\begin{bmatrix}\n",
    "    Y_i - X_i \\times \\theta_1\n",
    "\\end{bmatrix} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04df6227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Ratio Estimator\n",
      "=========================================================\n",
      "M-Estimation: single estimating equation\n",
      "Theta: [2.08234516]\n",
      "Var:   [[0.33842324]]\n",
      "---------------------------------------------------------\n",
      "Closed-Form\n",
      "Ratio: 2.0823451609959682\n",
      "Var:   0.33842329733168625\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def psi_ratio(theta):\n",
    "    return data['Y'] - data['X']*theta\n",
    "\n",
    "\n",
    "estr = MEstimator(psi_ratio, init=[0, ])\n",
    "estr.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Ratio Estimator\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation: single estimating equation\")\n",
    "print(\"Theta:\", estr.theta)\n",
    "print(\"Var:  \",estr.asymptotic_variance)\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Closed-Form\")\n",
    "\n",
    "theta = np.mean(data['Y']) / np.mean(data['X'])\n",
    "b = 1 / np.mean(data['X'])**2\n",
    "c = np.mean((data['Y'] - theta*data['X'])**2)\n",
    "var = b * c\n",
    "print(\"Ratio:\",theta)\n",
    "print(\"Var:  \",var)\n",
    "\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0236a",
   "metadata": {},
   "source": [
    "The next example is the ratio estimator consisting of 3 estimating equations. \n",
    "\n",
    "$$\\psi(Y_i, \\theta) = \n",
    "\\begin{bmatrix}\n",
    "    Y_i - \\theta_1\\\\\n",
    "    X_i - \\theta_2\\\\\n",
    "    \\theta_1 - \\theta_2 \\theta_3\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "Note that the last element is the ratio. To keep the dimensions correct, the last element needs to be multiplied by an array of $n$ constants. This is done via the `np.ones` trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c63d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Ratio Estimator\n",
      "=========================================================\n",
      "M-Estimation: three estimating equations\n",
      "Theta: [10.16284625  4.88048112  2.08234516]\n",
      "Var:  \n",
      " [[ 4.11208409  0.04326813  0.82409594]\n",
      " [ 0.04326813  0.95223623 -0.39742309]\n",
      " [ 0.82409594 -0.39742309  0.33842314]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def psi_ratio_three(theta):\n",
    "    return (data['Y'] - theta[0],\n",
    "            data['X'] - theta[1],\n",
    "            np.ones(data.shape[0])*theta[0] - theta[1]*theta[2])\n",
    "\n",
    "\n",
    "estr = MEstimator(psi_ratio_three, init=[0.1, 0.1, 0.1])\n",
    "estr.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Ratio Estimator\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation: three estimating equations\")\n",
    "print(\"Theta:\", estr.theta)\n",
    "print(\"Var:  \\n\", estr.asymptotic_variance)\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0c13a",
   "metadata": {},
   "source": [
    "### 7.2.4 Delta Method via M-Estimation\n",
    "M-estimation also allows for a generalization of the delta method. Below is an example with two transformations\n",
    "\n",
    "$$\\psi(Y_i, \\theta) = \n",
    "\\begin{bmatrix}\n",
    "    Y_i - \\theta_1\\\\\n",
    "    (Y_i - \\theta_1)^2 - \\theta_2\\\\\n",
    "    \\sqrt{\\theta_2} - \\theta_3\\\\\n",
    "    \\log(\\theta_2) - \\theta_4\n",
    "\\end{bmatrix} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a05e8716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Delta Method\n",
      "=========================================================\n",
      "M-Estimation\n",
      "Theta: [10.16284625  4.11208477  2.0278276   1.41393014]\n",
      "Var:  \n",
      " [[ 0.02056042 -0.00837    -0.00206379 -0.00203546]\n",
      " [-0.00837     0.18081933  0.04458452  0.04397267]\n",
      " [-0.00206379  0.04458452  0.01099318  0.01084232]\n",
      " [-0.00203546  0.04397267  0.01084232  0.01069352]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def psi_delta(theta):\n",
    "    return (data['Y'] - theta[0],\n",
    "            (data['Y'] - theta[0])**2 - theta[1],\n",
    "            np.ones(data.shape[0])*np.sqrt(theta[1]) - theta[2],\n",
    "            np.ones(data.shape[0])*np.log(theta[1]) - theta[3])\n",
    "\n",
    "\n",
    "estr = MEstimator(psi_delta, init=[1., 1., 1., 1.])\n",
    "estr.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Delta Method\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation\")\n",
    "print(\"Theta:\", estr.theta)\n",
    "print(\"Var:  \\n\", estr.variance)\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b0a530",
   "metadata": {},
   "source": [
    "### 7.2.6 Instrumental Variable Estimation\n",
    "Two variations on the estimating equations for instrumental variable analyses. $X$ is the exposure of interest, $X^*$ is the mismeasured or observed values of $X$, $I$ is the instrument for $X$, and $Y$ is the outcome of interest. We are interested in estimating $\\beta_1$ of:\n",
    "$$Y_i = \\beta_0 + \\beta_1 X_i + e_{i,j}$$\n",
    "Since $X^*$ is mismeasured, we can't immediately estimated $\\beta_1$. Instead, we need to use an instrumental variable approach. Below is some generated data consistent with this measurment error story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440d11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating some data\n",
    "n = 500\n",
    "data = pd.DataFrame()\n",
    "data['X'] = np.random.normal(size=n)\n",
    "data['Y'] = 0.5 + 2*data['X'] + np.random.normal(loc=0, size=n)\n",
    "data['X-star'] = data['X'] + np.random.normal(loc=0, size=n)\n",
    "data['T'] = -0.75 - 1*data['X'] + np.random.normal(loc=0, size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c8862d",
   "metadata": {},
   "source": [
    "The estimating equations are\n",
    "$$\\psi(Y_i,X_i^*,T_i, \\theta) = \n",
    "\\begin{bmatrix}\n",
    "    T_i - \\theta_1\\\\\n",
    "    (Y_i - \\theta_2X_i^*)(\\theta_1 - T_i)\n",
    "\\end{bmatrix} $$\n",
    "where $\\theta_1$ is the mean of the instrument, and $\\theta_2$ corresponds to $\\beta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d19de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Instrumental Variable\n",
      "=========================================================\n",
      "M-Estimation\n",
      "Theta: [-0.89989957  2.01777751]\n",
      "Var:  \n",
      " [[ 0.00430115 -0.0006694 ]\n",
      " [-0.0006694   0.023841  ]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def psi_instrument(theta):\n",
    "    return (theta[0] - data['T'],\n",
    "            (data['Y'] - data['X-star']*theta[1])*(theta[0] - data['T']))\n",
    "\n",
    "\n",
    "estr = MEstimator(psi_instrument, init=[0.1, 0.1])\n",
    "estr.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Instrumental Variable\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation\")\n",
    "print(\"Theta:\", estr.theta)\n",
    "print(\"Var:  \\n\", estr.variance)\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773839d",
   "metadata": {},
   "source": [
    "Another set of estimating equations for this instrumental variable approach is\n",
    "$$\\psi(Y_i,X_i^*,T_i, \\theta) = \n",
    "\\begin{bmatrix}\n",
    "    T_i - \\theta_1\\\\\n",
    "    \\theta_2 - X_i^* \\\\\n",
    "    (Y_i - \\theta_3 X_i^*)(\\theta_2 - X_i^*)\\\\\n",
    "    (Y_i - \\theta_4 X_i^*)(\\theta_1 - T_i)\n",
    "\\end{bmatrix} $$\n",
    "This set of estimating equations further allows for inference on the difference between $\\beta_1$ minus the coefficient for $Y$ given $X^*$. Here, $\\theta_1$ is the mean of the instrument, $\\theta_2$ is the mean of the mismeasured value of $X$, and $\\theta_3$ corresponds to the coefficient for $Y$ given $X^*$, and $\\theta_4$ is $\\beta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc959890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Instrumental Variable\n",
      "=========================================================\n",
      "M-Estimation\n",
      "Theta: [-0.89989957  0.02117577  0.95717618  2.01777751]\n",
      "Var:  \n",
      " [[ 0.00430115 -0.00207361 -0.00011136 -0.0006694 ]\n",
      " [-0.00207361  0.0041239   0.00023703  0.00039778]\n",
      " [-0.00011136  0.00023703  0.00302462  0.00171133]\n",
      " [-0.0006694   0.00039778  0.00171133  0.023841  ]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def psi(theta):\n",
    "    return (theta[0] - data['T'],\n",
    "            theta[1] - data['X-star'],\n",
    "            (data['Y'] - data['X-star']*theta[2])*(theta[1] - data['X-star']),\n",
    "            (data['Y'] - data['X-star']*theta[3])*(theta[0] - data['T'])\n",
    "            )\n",
    "\n",
    "\n",
    "estr = MEstimator(psi, init=[0.1, 0.1, 0.1, 0.1])\n",
    "estr.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Instrumental Variable\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation\")\n",
    "print(\"Theta:\", estr.theta)\n",
    "print(\"Var:  \\n\", estr.variance)\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be6f612",
   "metadata": {},
   "source": [
    "### 7.4.1 Robust Location Estimation\n",
    "The robust location estimator reduces the influence of outliers by applying bounds. The robust mean with a simple bounding function is\n",
    "   \n",
    "$$\\psi(Y_i, \\theta_1) = g_k(Y_i) - \\theta_1$$\n",
    "\n",
    "where $k$ indicates the bound, such that if $Y_i>k$ then $k$, or $Y_i<-k$ then $-k$, otherwise $Y_i$. Below is the estimating equation translated into code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b42c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating some generic data\n",
    "y = np.random.normal(size=250)\n",
    "n = y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3199896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Robust Location Estimation\n",
      "=========================================================\n",
      "M-Estimation\n",
      "Theta: [0.03056108]\n",
      "Var:  \n",
      " [[0.00370521]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def psi_robust_mean(theta):\n",
    "    k = 3                          # Bound value\n",
    "    yr = np.where(y > k, k, y)     # Applying upper bound\n",
    "    yr = np.where(y < -k, -k, y)   # Applying lower bound\n",
    "    return yr - theta\n",
    "\n",
    "\n",
    "estr = MEstimator(psi_robust_mean, init=[0.])\n",
    "estr.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Robust Location Estimation\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation\")\n",
    "print(\"Theta:\", estr.theta)\n",
    "print(\"Var:  \\n\", estr.variance)\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb9841",
   "metadata": {},
   "source": [
    "### 7.4.2 Quantile Estimation\n",
    "The previous estimating equation was non-smooth. Here, we consider another non-smooth function: quantiles. The estimating equations for quantiles are\n",
    "\n",
    "$$\\psi_q(Y_i, \\theta_1) = q - I(Y_i <= \\theta_1)$$ \n",
    "\n",
    "Due to the non-smooth nature, this estimating equation can be a little difficult to optimizer. Consider if the median is actually 0.55 but the next observation in terms of value is 0.57. This means that the estimating equation is 0 for all values between $[0.55, 0.57)$. \n",
    "\n",
    "To handle these issues in `delicatessen`, we will use a different root-finding algorithm, and a higher tolerance value. Furthermore, we adjust the `dx` and `order` values for the numerical approximation of the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2985645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Quantiles\n",
      "=========================================================\n",
      "M-Estimation\n",
      "Theta: [-0.71064081  0.10309617  0.67848129]\n",
      "Var:  \n",
      " [[0.02106748 0.00668387 0.00409554]\n",
      " [0.00668387 0.00687221 0.00420896]\n",
      " [0.00409554 0.00420896 0.00765179]]\n",
      "---------------------------------------------------------\n",
      "Closed-Form\n",
      "[-0.65124657  0.10838232  0.68413976]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def psi_quantile(theta):\n",
    "    return (0.25 - 1*(y <= theta[0]),\n",
    "            0.50 - 1*(y <= theta[1]),\n",
    "            0.75 - 1*(y <= theta[2]),)\n",
    "\n",
    "\n",
    "estr = MEstimator(psi_quantile, init=[0., 0., 0.])\n",
    "estr.estimate(solver='hybr',   # Selecting the hybr method\n",
    "              tolerance=1e-3,  # Increasing the tolerance\n",
    "              dx=0.1,          # Increasing distance for numerical approx\n",
    "              order=25)        # Increasing the number of points for numerical approx\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Quantiles\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation\")\n",
    "print(\"Theta:\", estr.theta)\n",
    "print(\"Var:  \\n\", estr.variance)\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Closed-Form\")\n",
    "print(np.quantile(y, q=[0.25, 0.50, 0.75]))\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0732cc12",
   "metadata": {},
   "source": [
    "Notice that there is a difference between the M-Estimation and the closed-form. This occurs for the reason described above. Furthermore, the variances are sensitive to changes in `dx`, so they should not be considered reliable.\n",
    "\n",
    "### 7.4.3 Positive Mean Deviation\n",
    "A related parameter is the positive mean deviation, which describes the mean for observations above the median. The estimating equations are\n",
    "$$\\psi(Y_i; \\theta) = \n",
    "\\begin{bmatrix}\n",
    "    2(Y_i - \\theta_2)I(Y_i > \\theta_2) - \\theta_1\\\\\n",
    "    0.5 - I(Y_i \\le \\theta_2)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "As before, the median is non-smooth. Therefore, we need to revise the parameters and our optimization approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd0bfe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Positive Mean Deviation\n",
      "=========================================================\n",
      "M-Estimation\n",
      "[0.69144095 0.10605091]\n",
      "[[ 0.00381667 -0.002829  ]\n",
      " [-0.002829    0.00625453]]\n",
      "---------------------------------------------------------\n",
      "Closed-Form\n",
      "0.6891092946789333 0.10838231523145117\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def psi_deviation(theta):\n",
    "    return ((2 * (y - theta[1]) * (y > theta[1])) - theta[0],\n",
    "            1/2 - (y <= theta[1]), )\n",
    "\n",
    "\n",
    "estr = MEstimator(psi_deviation, init=[0.0, 0.0, ])\n",
    "estr.estimate(solver='hybr',   # Selecting the hybr method\n",
    "              tolerance=1e-3,  # Increasing the tolerance\n",
    "              dx=0.1,          # Increasing distance for numerical approx\n",
    "              order=25)        # Increasing the number of points for numerical approx\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Positive Mean Deviation\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation\")\n",
    "print(estr.theta)\n",
    "print(estr.variance)\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Closed-Form\")\n",
    "median = np.median(y)\n",
    "v = 2/n * np.sum((y - median) * (y > median))\n",
    "print(v, median)\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a7ab03",
   "metadata": {},
   "source": [
    "### 7.5.1 Linear Model with Random $X$\n",
    "Next, we can run a linear regression model. Note that the variance here is robust (to violations of the homoscedastic assumption). Note that we need to manually add an intercept (the column `C` in the data). As comparison, we provide the equivalent using `statsmodels` generalized linear model with heteroscedastic-corrected variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "592d77d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Linear Model\n",
      "=========================================================\n",
      "M-Estimation: by-hand\n",
      "[ 0.41082601  1.96289222 -1.02663555]\n",
      "[[ 2.18524079e-03  7.28169639e-05  1.54216620e-04]\n",
      " [ 7.28169639e-05  2.08315655e-03 -4.09519996e-05]\n",
      " [ 1.54216620e-04 -4.09519996e-05  2.14573736e-03]]\n",
      "---------------------------------------------------------\n",
      "GLM Estimator\n",
      "[ 0.41082601  1.96289222 -1.02663555]\n",
      "[[ 2.18524092e-03  7.28169947e-05  1.54216630e-04]\n",
      " [ 7.28169947e-05  2.08315690e-03 -4.09519947e-05]\n",
      " [ 1.54216630e-04 -4.09519947e-05  2.14573770e-03]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "data = pd.DataFrame()\n",
    "data['X'] = np.random.normal(size=n)\n",
    "data['Z'] = np.random.normal(size=n)\n",
    "data['Y'] = 0.5 + 2*data['X'] - 1*data['Z'] + np.random.normal(size=n)\n",
    "data['C'] = 1\n",
    "\n",
    "\n",
    "def psi_regression(theta):\n",
    "    x = np.asarray(data[['C', 'X', 'Z']])\n",
    "    y = np.asarray(data['Y'])[:, None]\n",
    "    beta = np.asarray(theta)[:, None]\n",
    "    return ((y - np.dot(x, beta)) * x).T\n",
    "\n",
    "\n",
    "mestimator = MEstimator(psi_regression, init=[0.1, 0.1, 0.1])\n",
    "mestimator.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Linear Model\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation: by-hand\")\n",
    "print(mestimator.theta)\n",
    "print(mestimator.variance)\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n",
    "print(\"GLM Estimator\")\n",
    "glm = smf.glm(\"Y ~ X + Z\", data).fit(cov_type=\"HC1\")\n",
    "print(np.asarray(glm.params))\n",
    "print(np.asarray(glm.cov_params()))\n",
    "\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d8774c",
   "metadata": {},
   "source": [
    "The following uses the built-in linear regression functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4762b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Linear Model\n",
      "=========================================================\n",
      "M-Estimation: built-in\n",
      "[ 0.41082601  1.96289222 -1.02663555]\n",
      "[[ 2.18524079e-03  7.28169639e-05  1.54216620e-04]\n",
      " [ 7.28169639e-05  2.08315655e-03 -4.09519996e-05]\n",
      " [ 1.54216620e-04 -4.09519996e-05  2.14573736e-03]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "from delicatessen.estimating_equations import ee_linear_regression\n",
    "\n",
    "def psi_regression(theta):\n",
    "    return ee_linear_regression(theta=theta,\n",
    "                                X=data[['C', 'X', 'Z']],\n",
    "                                y=data['Y'])\n",
    "\n",
    "\n",
    "mestimator = MEstimator(psi_regression, init=[0.1, 0.1, 0.1])\n",
    "mestimator.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Linear Model\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation: built-in\")\n",
    "print(mestimator.theta)\n",
    "print(mestimator.variance)\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b41d09",
   "metadata": {},
   "source": [
    "### 7.5.4 Robust Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dd6f38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Linear Model\n",
      "=========================================================\n",
      "M-Estimation: by-hand\n",
      "[ 0.41223641  1.95577495 -1.02508413]\n",
      "[[ 2.31591834e-03  1.82106059e-04  2.57209790e-04]\n",
      " [ 1.82106059e-04  2.12098791e-03 -6.95782387e-05]\n",
      " [ 2.57209790e-04 -6.95782387e-05  2.38212555e-03]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def psi_robust_regression(theta):\n",
    "    k = 1.345    \n",
    "    x = np.asarray(data[['C', 'X', 'Z']])\n",
    "    y = np.asarray(data['Y'])[:, None]\n",
    "    beta = np.asarray(theta)[:, None]\n",
    "    preds = np.clip(y - np.dot(x, beta), -k, k)\n",
    "    return (preds * x).T\n",
    "\n",
    "\n",
    "mestimator = MEstimator(psi_robust_regression, init=[0.5, 2., -1.])\n",
    "mestimator.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Linear Model\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation: by-hand\")\n",
    "print(mestimator.theta)\n",
    "print(mestimator.variance)\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6853cbf2",
   "metadata": {},
   "source": [
    "The following uses the built-in robust linear regression functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84eea92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Linear Model\n",
      "=========================================================\n",
      "M-Estimation: built-in\n",
      "[ 0.41223641  1.95577495 -1.02508413]\n",
      "[[ 2.31591834e-03  1.82106059e-04  2.57209790e-04]\n",
      " [ 1.82106059e-04  2.12098791e-03 -6.95782387e-05]\n",
      " [ 2.57209790e-04 -6.95782387e-05  2.38212555e-03]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "from delicatessen.estimating_equations import ee_robust_linear_regression\n",
    "\n",
    "def psi_robust_regression(theta):\n",
    "    return ee_robust_linear_regression(theta=theta,\n",
    "                                       X=data[['C', 'X', 'Z']],\n",
    "                                       y=data['Y'],\n",
    "                                       k=1.345)\n",
    "\n",
    "mestimator = MEstimator(psi_robust_regression, init=[0.5, 2., -1.])\n",
    "mestimator.estimate()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"Linear Model\")\n",
    "print(\"=========================================================\")\n",
    "print(\"M-Estimation: built-in\")\n",
    "print(mestimator.theta)\n",
    "print(mestimator.variance)\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567903cc",
   "metadata": {},
   "source": [
    "End of tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
