{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b551623",
   "metadata": {},
   "source": [
    "# M-Estimation for multiple biases\n",
    "In this tutorial, we will demonstrate how the M-Estimation framework can easily be used to address multiple biases. In this particular example, we will address confounding, missing data, and generalizability. To showcase how estimating equations can be stacked together, these biases will be addressed iteratively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec14bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version:        1.19.5\n",
      "SciPy version:        1.5.4\n",
      "Pandas version:       1.1.5\n",
      "Delicatessen version: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Initial setup\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import delicatessen\n",
    "from delicatessen import MEstimator\n",
    "from delicatessen.estimating_equations import ee_logistic_regression \n",
    "from delicatessen.estimating_equations import ee_ridge_linear_regression\n",
    "from delicatessen.utilities import inverse_logit\n",
    "\n",
    "np.random.seed(51520837)\n",
    "\n",
    "print(\"NumPy version:       \", np.__version__)\n",
    "print(\"SciPy version:       \", sp.__version__)\n",
    "print(\"Pandas version:      \", pd.__version__)\n",
    "print(\"Delicatessen version:\", delicatessen.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27deef80",
   "metadata": {},
   "source": [
    "## Motivating Problem\n",
    "We are interested in estimating the average causal effect of action $A$ on the outcome $Y$. We can express this parameter as \n",
    "$$E[Y^{a=1}] - E[Y^{a=0}]$$\n",
    "where $Y^a$ is the potential outcome under action $a$. To estimate this quantity, we will need some assumptions and some data. To express how the data is generated, I will create a DAG using `zEpid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1389e304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from zepid.causal.causalgraph import DirectedAcyclicGraph\n",
    "from zepid.graphics import pvalue_plot\n",
    "\n",
    "dag = DirectedAcyclicGraph(exposure=\"A\", outcome=\"Y\")\n",
    "dag.add_arrows(pairs=((\"A\", \"Y\"), \n",
    "                      (\"W\", \"Y\"), (\"W\", \"A\"),\n",
    "                      (\"V\", r\"$R_Y$\"), (\"V\", \"Y\"),\n",
    "                      (\"X\", \"S\"), (\"X\", \"Y\")))\n",
    "pos = {\"A\": [0, 0], \"Y\": [1, 0], \"W\": [-1, 0.75],\n",
    "       \"V\": [-0.25, 1], r\"$R_Y$\": [1, 1], \n",
    "       \"X\": [-0.25, -0.75], \"S\": [1, -0.75]}\n",
    "dag.draw_dag(positions=pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd6276e",
   "metadata": {},
   "source": [
    "where $W,V,X$ are baseline variables, $R_Y$ is an indicator for missingness of $Y$, and $S$ is selection into the sample (e.g., not a random sample of the target population). \n",
    "\n",
    "Therefore, there are 3 sources of biases we need to address: confounding of $A$ and $Y$ by $W$, informative missing by $V$, and differences in the distribution of $X$ between the analytic sample and the target population. Below is a data generating procedure consistent with the causal diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135f08ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9776229939112391\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>V</th>\n",
       "      <th>X</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>77016.000000</td>\n",
       "      <td>63093.000000</td>\n",
       "      <td>77016.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000878</td>\n",
       "      <td>1.001040</td>\n",
       "      <td>1.499450</td>\n",
       "      <td>0.329607</td>\n",
       "      <td>26.996165</td>\n",
       "      <td>0.819219</td>\n",
       "      <td>0.770160</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001275</td>\n",
       "      <td>0.816422</td>\n",
       "      <td>1.118272</td>\n",
       "      <td>0.470073</td>\n",
       "      <td>2.010666</td>\n",
       "      <td>0.384839</td>\n",
       "      <td>0.420732</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.244768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.305299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.671614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.729811</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.005925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.672114</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.258917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.668929</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.124759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   W              V              X             A  \\\n",
       "count  100000.000000  100000.000000  100000.000000  77016.000000   \n",
       "mean        0.000878       1.001040       1.499450      0.329607   \n",
       "std         1.001275       0.816422       1.118272      0.470073   \n",
       "min        -4.244768       0.000000       0.000000      0.000000   \n",
       "25%        -0.671614       0.000000       0.000000      0.000000   \n",
       "50%         0.002279       1.000000       1.000000      0.000000   \n",
       "75%         0.672114       2.000000       3.000000      1.000000   \n",
       "max         4.668929       2.000000       3.000000      1.000000   \n",
       "\n",
       "                  Y             R              S         C  \n",
       "count  63093.000000  77016.000000  100000.000000  100000.0  \n",
       "mean      26.996165      0.819219       0.770160       1.0  \n",
       "std        2.010666      0.384839       0.420732       0.0  \n",
       "min       19.305299      0.000000       0.000000       1.0  \n",
       "25%       25.729811      1.000000       1.000000       1.0  \n",
       "50%       27.005925      1.000000       1.000000       1.0  \n",
       "75%       28.258917      1.000000       1.000000       1.0  \n",
       "max       36.124759      1.000000       1.000000       1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100000  # Generating lots of observations to reduce randomness\n",
    "\n",
    "# Generating baseline covariates\n",
    "d = pd.DataFrame()\n",
    "d['W'] = np.random.normal(size=n)\n",
    "d['V'] = np.random.randint(0, 3, size=n)\n",
    "d['X'] = np.random.randint(0, 4, size=n)\n",
    "\n",
    "# Generating actions\n",
    "pr_a = sp.stats.logistic.cdf(-0.8 + 0.7*d['W'])\n",
    "d['A'] = np.random.binomial(n=1, p=pr_a,\n",
    "                            size=n)\n",
    "\n",
    "# Generating potential outcomes\n",
    "d['Ya1'] = (25 + 2 - 0.95*d['W'] \n",
    "            + 0*(d['V']==1) + 1*(d['V']==2)\n",
    "            + 2.5*(d['X']==1) + 1.5*(d['X']==2) + 1.5*(d['X']==3)\n",
    "            - 3*1*(d['V']==1) + 1.5*1*(d['V']==2)            \n",
    "            - 0.6*1*(d['X']==2) - 1.5*1*(d['X']==3)\n",
    "            + np.random.normal(size=n))\n",
    "d['Ya0'] = (25 + 0 - 0.95*d['W'] \n",
    "            + 0*(d['V']==1) + 1*(d['V']==2)\n",
    "            + 2.5*(d['X']==1) + 1.5*(d['X']==2) + 1.5*(d['X']==3)\n",
    "            - 3*0*(d['V']==1) + 1.5*0*(d['V']==2)            \n",
    "            - 0.6*0*(d['X']==2) - 1.5*0*(d['X']==3)\n",
    "            + np.random.normal(size=n))\n",
    "# Generating outcomes via causal consistency\n",
    "d['Y'] = np.where(d['A'] == 1, d['Ya1'], d['Ya0'])\n",
    "\n",
    "# Generating informative missing\n",
    "pr_r = sp.stats.logistic.cdf(3\n",
    "                             + 4*(d['V']==1) \n",
    "                             - 3*(d['V']==2))\n",
    "d['R'] = np.random.binomial(n=1, p=pr_r,\n",
    "                            size=n)\n",
    "d['Y'] = np.where(d['R'] == 1, d['Y'], np.nan)\n",
    "\n",
    "# Generating selection into sample\n",
    "pr_s = sp.stats.logistic.cdf(- 1*(d['X']==0)\n",
    "                             + 2*(d['X']==1)\n",
    "                             + 3*(d['X']==2) \n",
    "                             + 4*(d['X']==3))\n",
    "d['S'] = np.random.binomial(n=1, p=pr_s,\n",
    "                            size=n)\n",
    "d['A'] = np.where(d['S'] == 1, d['A'], np.nan) # Hiding A,R,Y if not in S=1\n",
    "d['R'] = np.where(d['S'] == 1, d['R'], np.nan)\n",
    "d['Y'] = np.where(d['S'] == 1, d['Y'], np.nan)\n",
    "\n",
    "# Uncomment these lines to see how ACE estimates change over biases\n",
    "# print(np.mean(d.loc[d['A']==1, 'Y']) - np.mean(d.loc[d['A']==0, 'Y']))\n",
    "# print(np.mean(d.loc[d['R']==1, 'Ya1'] - d.loc[d['R']==1, 'Ya0']))\n",
    "# print(np.mean(d.loc[d['S']==1, 'Ya1'] - d.loc[d['S']==1, 'Ya0']))\n",
    "print(np.mean(d['Ya1'] - d['Ya0']))\n",
    "\n",
    "# Data we get to see\n",
    "ds = d[[\"W\", \"V\", \"X\", \"A\", \"Y\", \"R\", \"S\"]].copy()\n",
    "ds['C'] = 1\n",
    "ds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b45dd",
   "metadata": {},
   "source": [
    "## Naive Mean\n",
    "As a start, we will estimate the naive mean. The naive mean ignores all the sources of bias. This can be implemented easily using `delicatessen`, where we just use estimating equations for the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4c26437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Naive\n",
      "======================================\n",
      "ACE:    -0.185\n",
      "95% CI: [-0.224 -0.145]\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# Extracting covariates for use in psi()\n",
    "d = ds.dropna().copy()\n",
    "A = np.asarray(d['A'])\n",
    "y = np.asarray(d['Y'])\n",
    "\n",
    "\n",
    "def psi_naive(theta):\n",
    "    ya1 = np.asarray((A == 1)*np.where(d['Y'].isna(), 0, y - theta[1]))\n",
    "    ya0 = np.asarray((A == 0)*np.where(d['Y'].isna(), 0, y - theta[2]))\n",
    "    ace = np.ones(d.shape[0])*(theta[1] - theta[2]) - theta[0]\n",
    "    return (ace,\n",
    "            ya1,\n",
    "            ya0)\n",
    "\n",
    "# deal with missing....\n",
    "estr0 = MEstimator(psi_naive, init=[0, 0, 0])\n",
    "estr0.estimate(solver='lm')\n",
    "\n",
    "naive_ace = estr0.theta[0]\n",
    "naive_var = estr0.variance[0, 0]\n",
    "naive_ci = estr0.confidence_intervals()[0, :]\n",
    "\n",
    "print(\"======================================\")\n",
    "print(\"Naive\")\n",
    "print(\"======================================\")\n",
    "print(\"ACE:   \", np.round(naive_ace, 3))\n",
    "print(\"95% CI:\", np.round(naive_ci, 3))\n",
    "print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d0fd82",
   "metadata": {},
   "source": [
    "## Confounding\n",
    "For the first bias, let's deal with confounding. In order to address confounding, we make the following identification assumptions\n",
    "$$Y_i = Y_i^a \\text{ if } a=A_i$$\n",
    "$$E[Y^a|W=w] = E[Y^a|A=a,W=w]$$\n",
    "$$\\Pr(A=a|W=w) > 0 \\text{ for all } a\\in\\{0,1\\}, w$$\n",
    "where the first assumption is causal consistency, the second assumption is conditional exchangeability, and the third assumption is positivity. Therefore, we can address confounding using inverse probability weights. \n",
    "$$\\pi_A(W_i) = \\Pr(A_i=a, W_i=w)$$\n",
    "Since $W$ is continuous and the probabilities are unknown, we will be using a parametric logistic model to estimate $\\Pr(A=a|W=w)$. \n",
    "\n",
    "To add this to our estimating equation, we will further stack an estimating equation for the logistic model into the previous stacked estimating equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6893a801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.37747308 27.23767158 26.8601985  -0.78648158  0.71299207]\n",
      "======================================\n",
      "Accounting for Confounding\n",
      "======================================\n",
      "ACE:    0.377\n",
      "95% CI: [0.276 0.479]\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# Extracting covariates for use in psi()\n",
    "d = ds.dropna().copy()\n",
    "W = np.asarray(d[['C', 'W']])\n",
    "A = np.asarray(d['A'])\n",
    "y = np.asarray(d['Y'])\n",
    "\n",
    "\n",
    "def psi_cnfdr(theta):\n",
    "    beta = theta[3:]\n",
    "    \n",
    "    # Estimating Pr(A=1|W=w) and weights\n",
    "    a_model = ee_logistic_regression(beta, \n",
    "                                      X=W, y=A)\n",
    "    pi_a = inverse_logit(np.dot(W, beta))\n",
    "    pi_a = np.clip(pi_a, 0.01, 0.99)\n",
    "    \n",
    "    # Creating IPW\n",
    "    ipw = np.where(A==1, 1/pi_a, 1/(1-pi_a))\n",
    "\n",
    "    # Calculating ACE\n",
    "    ya1 = np.where(d['Y'].isna(), 0, (A*y)*ipw - theta[1])\n",
    "    ya0 = np.where(d['Y'].isna(), 0, ((1-A)*y)*ipw - theta[2])\n",
    "    ace = np.ones(y.shape[0]) * (theta[1] - theta[2]) - theta[0]\n",
    "    return np.vstack((ace,\n",
    "                      ya1[None, :],\n",
    "                      ya0[None, :],\n",
    "                      a_model))\n",
    "\n",
    "# deal with missing....\n",
    "starting_vals = list(estr0.theta) + [0, 0]\n",
    "estr1 = MEstimator(psi_cnfdr, init=starting_vals)\n",
    "estr1.estimate(solver='lm')\n",
    "\n",
    "cnfdr_ace = estr1.theta[0]\n",
    "cnfdr_var = estr1.variance[0, 0]\n",
    "cnfdr_ci = estr1.confidence_intervals()[0, :]\n",
    "\n",
    "print(estr1.theta)\n",
    "print(\"======================================\")\n",
    "print(\"Accounting for Confounding\")\n",
    "print(\"======================================\")\n",
    "print(\"ACE:   \", np.round(cnfdr_ace, 3))\n",
    "print(\"95% CI:\", np.round(cnfdr_ci, 3))\n",
    "print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20654181",
   "metadata": {},
   "source": [
    "## Missing Outcomes\n",
    "Now that we've dealt with confounding, let's deal with the second source of bias: informative missing outcomes. In order to address the informative missingness, we make the following identification assumptions\n",
    "$$E[Y^a|W=w] = E[Y^a|R=1,W=w]$$\n",
    "$$\\Pr(R=1|W=w) > 0 \\text{ for all } v$$\n",
    "where the first assumption is conditional exchangeability, and the second is positivity. Therefore, we can address missing outcomes using another set of inverse probability weights. \n",
    "$$\\pi_R(V_i) = \\Pr(R_i=1, V_i=v)$$\n",
    "As in the confounding case, these probabilities are unknown and must be estimated. Similarly, we use a parametric logistic model to estimate $\\Pr(R=1|V=v)$. \n",
    "\n",
    "Therefore, we will stack an additional logistic model to our previous estimating equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f29ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Accounting for Confounding, Missing Y\n",
      "======================================\n",
      "ACE:    0.906\n",
      "95% CI: [0.603 1.209]\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# Extracting covariates for use in psi()\n",
    "d = ds.loc[ds['S'] == 1].copy()\n",
    "d['V1'] = np.where(d['V']==1, 1, 0)\n",
    "d['V2'] = np.where(d['V']==2, 1, 0)\n",
    "V = np.asarray(d[['C', 'V1', 'V2']])\n",
    "R = np.asarray(d['R'])\n",
    "W = np.asarray(d[['C', 'W']])\n",
    "A = np.asarray(d['A'])\n",
    "y = np.asarray(d['Y'])\n",
    "\n",
    "\n",
    "def psi_mssng(theta, print_p=False):\n",
    "    beta = theta[3:5]\n",
    "    alpha = theta[5:]\n",
    "    \n",
    "    # Estimating Pr(A=1|W=w) and weights\n",
    "    a_model = ee_logistic_regression(beta, \n",
    "                                      X=W, y=A)\n",
    "    pi_a = inverse_logit(np.dot(W, beta))\n",
    "    # pi_a = np.clip(pi_a, 0.01, 0.99)\n",
    "\n",
    "    # Estimating Pr(R=1|V=v) and weights\n",
    "    m_model = ee_logistic_regression(alpha, \n",
    "                                      X=V, y=R)\n",
    "    pi_m = inverse_logit(np.dot(V, alpha))\n",
    "    # pi_m = np.clip(pi_m, 0.01, 0.99)\n",
    "\n",
    "    # Creating IPW\n",
    "    ipw = np.where(A==1, 1/(pi_a*pi_m), 1/((1-pi_a)*pi_m))\n",
    "    if print_p:\n",
    "        print(ipw)\n",
    "    \n",
    "    # Calculating ACE\n",
    "    ya1 = np.nan_to_num((y*A*ipw), copy=False, nan=0.) - theta[1]\n",
    "    ya0 = np.where(d['Y'].isna(), 0, ((1-A)*y)*ipw) - theta[2]\n",
    "    ace = np.ones(y.shape[0]) * (theta[1] - theta[2]) - theta[0]\n",
    "    return np.vstack((ace,\n",
    "                      ya1[None, :],\n",
    "                      ya0[None, :],\n",
    "                      a_model,\n",
    "                      m_model))\n",
    "\n",
    "# deal with confounding, missing....\n",
    "starting_vals = list(estr1.theta) + [0, 0, 0]\n",
    "estr2 = MEstimator(psi_mssng, init=starting_vals)\n",
    "estr2.estimate(solver='lm')\n",
    "\n",
    "mssng_ace = estr2.theta[0]\n",
    "mssng_var = estr2.variance[0, 0]\n",
    "mssng_ci = estr2.confidence_intervals()[0, :]\n",
    "\n",
    "print(\"======================================\")\n",
    "print(\"Accounting for Confounding, Missing Y\")\n",
    "print(\"======================================\")\n",
    "print(\"ACE:   \", np.round(mssng_ace, 3))\n",
    "print(\"95% CI:\", np.round(mssng_ci, 3))\n",
    "print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbdde96",
   "metadata": {},
   "source": [
    "## Generalizability\n",
    "The final source of bias we need to contend with is that our available data is not a random sample of our target population. Rather, there was some non-random selection into our sample, so the estimate from our sample may not apply to the target population. In order to account for this non-random selection, we make the following identification assumptions\n",
    "$$E[Y^a|X=x] = E[Y^a|S=s,X=x]$$\n",
    "$$\\Pr(S=1|X=x) > 0 \\text{ for all } x$$\n",
    "where the first assumption is conditional exchangeability, and the second is positivity. Therefore, we can address missing outcomes using another set of inverse probability weights. \n",
    "$$\\pi_S(X_i) = \\Pr(S_i=1, X_i=v)$$\n",
    "As in the confounding case, these probabilities are unknown and must be estimated. Similarly, we use a parametric logistic model to estimate $\\Pr(S=1|X=x)$. \n",
    "\n",
    "Therefore, we will stack an third logistic model to our previous estimating equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c560d918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99415403 27.76030501 26.76615098 -0.78926613  0.71435026  2.9976142\n",
      " 43.60414343 -2.97234954 -1.00864469  2.96941341  4.05451353  5.03848124]\n",
      "======================================\n",
      "Generalized ACE\n",
      "======================================\n",
      "ACE:    0.994\n",
      "95% CI: [0.574 1.414]\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# Extracting covariates for use in psi()\n",
    "ds['V1'] = np.where(ds['V']==1, 1, 0)\n",
    "ds['V2'] = np.where(ds['V']==2, 1, 0)\n",
    "ds['X1'] = np.where(ds['X']==1, 1, 0)\n",
    "ds['X2'] = np.where(ds['X']==2, 1, 0)\n",
    "ds['X3'] = np.where(ds['X']==3, 1, 0)\n",
    "X = np.asarray(ds[['C', 'X1', 'X2', 'X3']])\n",
    "S = np.asarray(ds['S'])\n",
    "V = np.asarray(ds[['C', 'V1', 'V2']])\n",
    "R = np.asarray(ds['R'])\n",
    "W = np.asarray(ds[['C', 'W']])\n",
    "A = np.asarray(ds['A'])\n",
    "y = np.asarray(ds['Y'])\n",
    "\n",
    "\n",
    "def psi_slctn(theta):\n",
    "    beta = theta[3:5]\n",
    "    alpha = theta[5:8]\n",
    "    gamma = theta[8:]\n",
    "    \n",
    "    # Estimating Pr(A=1|W=w) and weights\n",
    "    a_model = ee_logistic_regression(beta, \n",
    "                                      X=W, y=A)\n",
    "    a_model = np.nan_to_num(a_model, copy=False, nan=0.)\n",
    "    pi_a = inverse_logit(np.dot(W, beta))\n",
    "    pi_a = np.clip(pi_a, 0.01, 0.99)\n",
    "\n",
    "    # Estimating Pr(R=1|V=v) and weights\n",
    "    m_model = ee_logistic_regression(alpha, \n",
    "                                      X=V, y=R)\n",
    "    m_model = np.nan_to_num(m_model, copy=False, nan=0.)\n",
    "    pi_m = inverse_logit(np.dot(V, alpha))\n",
    "    pi_m = np.clip(pi_m, 0.01, 0.99)\n",
    "\n",
    "    # Estimating Pr(R=1|V=v) and weights\n",
    "    s_model = ee_logistic_regression(gamma, \n",
    "                                      X=X, y=S)\n",
    "    pi_s = inverse_logit(np.dot(X, gamma))\n",
    "    pi_s = np.clip(pi_s, 0.01, 0.99)\n",
    "\n",
    "    # Creating IPW\n",
    "    ipw = np.where(A==1, 1/(pi_a*pi_m*pi_s), 1/((1-pi_a)*pi_m*pi_s))\n",
    "    \n",
    "    # Calculating ACE\n",
    "    ya1 = np.where(ds['Y'].isna(), 0, (A*y)*ipw) - theta[1]\n",
    "    ya0 = np.where(ds['Y'].isna(), 0, ((1-A)*y)*ipw) - theta[2]\n",
    "    ace = np.ones(y.shape[0]) * (theta[1] - theta[2]) - theta[0]\n",
    "    return np.vstack((ace,\n",
    "                      ya1[None, :],\n",
    "                      ya0[None, :],\n",
    "                      a_model,\n",
    "                      m_model,\n",
    "                      s_model))\n",
    "\n",
    "# deal with confounding, missing, selection....\n",
    "starting_vals = list(estr2.theta) + [0, 0, 0, 0]\n",
    "estr3 = MEstimator(psi_slctn, init=starting_vals)\n",
    "estr3.estimate(solver='lm')\n",
    "\n",
    "slctn_ace = estr3.theta[0]\n",
    "slctn_var = estr3.variance[0, 0]\n",
    "slctn_ci = estr3.confidence_intervals()[0, :]\n",
    "\n",
    "print(estr3.theta)\n",
    "print(\"======================================\")\n",
    "print(\"Generalized ACE\")\n",
    "print(\"======================================\")\n",
    "print(\"ACE:   \", np.round(slctn_ace, 3))\n",
    "print(\"95% CI:\", np.round(slctn_ci, 3))\n",
    "print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce4e6b",
   "metadata": {},
   "source": [
    "## Improving Efficiency\n",
    "The IPW estimator(s) are inefficient. Here, we will \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6bd1017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.92338004e-01  2.76792363e+01  2.66868983e+01 -7.89266129e-01\n",
      "  7.14350264e-01  2.99761420e+00  4.36041434e+01 -2.97234954e+00\n",
      " -1.00864469e+00  2.96941341e+00  4.05451353e+00  5.03848124e+00\n",
      "  2.49918092e+01  2.00465869e+00 -9.49225942e-01 -1.64234439e-02\n",
      "  9.82332929e-01  2.50973252e+00  1.51544246e+00  1.51226104e+00\n",
      " -2.98144170e+00  1.49944507e+00 -1.01568024e-02 -6.14498874e-01\n",
      " -1.51129424e+00]\n",
      "======================================\n",
      "AIPW Estimator\n",
      "======================================\n",
      "ACE:    0.992\n",
      "95% CI: [0.601 1.384]\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "ds['V1'] = np.where(ds['V']==1, 1, 0)\n",
    "ds['V2'] = np.where(ds['V']==2, 1, 0)\n",
    "ds['X1'] = np.where(ds['X']==1, 1, 0)\n",
    "ds['X2'] = np.where(ds['X']==2, 1, 0)\n",
    "ds['X3'] = np.where(ds['X']==3, 1, 0)\n",
    "ds['A-V1'] = ds['A']*ds['V1']\n",
    "ds['A-V2'] = ds['A']*ds['V2']\n",
    "ds['A-X1'] = ds['A']*ds['X1']\n",
    "ds['A-X2'] = ds['A']*ds['X2']\n",
    "ds['A-X3'] = ds['A']*ds['X3']\n",
    "\n",
    "ds['A_all'] = 1\n",
    "ds['A1-V1'] = 1*ds['V1']\n",
    "ds['A1-V2'] = 1*ds['V2']\n",
    "ds['A1-X1'] = 1*ds['X1']\n",
    "ds['A1-X2'] = 1*ds['X2']\n",
    "ds['A1-X3'] = 1*ds['X3']\n",
    "\n",
    "ds['A_none'] = 0\n",
    "ds['A0-V1'] = 0*ds['V1']\n",
    "ds['A0-V2'] = 0*ds['V2']\n",
    "ds['A0-X1'] = 0*ds['X1']\n",
    "ds['A0-X2'] = 0*ds['X2']\n",
    "ds['A0-X3'] = 0*ds['X3']\n",
    "\n",
    "Z = np.asarray(ds[['C', 'A', 'W', 'V1', 'V2', \n",
    "                   'X1', 'X2', 'X3', 'A-V1', 'A-V2', \n",
    "                   'A-X1', 'A-X2', 'A-X3']])\n",
    "Za = np.asarray(ds[['C', 'A_all', 'W', 'V1', 'V2', \n",
    "                    'X1', 'X2', 'X3', 'A1-V1', 'A1-V2', \n",
    "                    'A1-X1', 'A1-X2', 'A1-X3']])\n",
    "Zn = np.asarray(ds[['C', 'A_none', 'W', 'V1', 'V2', \n",
    "                    'X1', 'X2', 'X3', 'A0-V1', 'A0-V2', \n",
    "                    'A0-X1', 'A0-X2', 'A0-X3']])\n",
    "X = np.asarray(ds[['C', 'X1', 'X2', 'X3']])\n",
    "S = np.asarray(ds['S'])\n",
    "V = np.asarray(ds[['C', 'V1', 'V2']])\n",
    "R = np.asarray(ds['R'])\n",
    "W = np.asarray(ds[['C', 'W']])\n",
    "A = np.asarray(ds['A'])\n",
    "y = np.asarray(ds['Y'])\n",
    "\n",
    "\n",
    "\n",
    "def psi_aipw(theta):\n",
    "    beta = theta[3:5]\n",
    "    alpha = theta[5:8]\n",
    "    gamma = theta[8:12]\n",
    "    delta = theta[12:]\n",
    "    \n",
    "    # Estimating Pr(A=1|W=w) and weights\n",
    "    a_model = ee_logistic_regression(beta, \n",
    "                                      X=W, y=A)\n",
    "    a_model = np.nan_to_num(a_model, copy=False, nan=0.)\n",
    "    pi_a = inverse_logit(np.dot(W, beta))\n",
    "    pi_a = np.clip(pi_a, 0.01, 0.99)\n",
    "\n",
    "    # Estimating Pr(R=1|V=v) and weights\n",
    "    m_model = ee_logistic_regression(alpha, \n",
    "                                      X=V, y=R)\n",
    "    m_model = np.nan_to_num(m_model, copy=False, nan=0.)\n",
    "    pi_m = inverse_logit(np.dot(V, alpha))\n",
    "    pi_m = np.clip(pi_m, 0.01, 0.99)\n",
    "\n",
    "    # Estimating Pr(R=1|V=v) and weights\n",
    "    s_model = ee_logistic_regression(gamma, \n",
    "                                      X=X, y=S)\n",
    "    pi_s = inverse_logit(np.dot(X, gamma))\n",
    "    pi_s = np.clip(pi_s, 0.01, 0.99)\n",
    "    \n",
    "    # Estimating E[Y|A,W,V,X]\n",
    "    y_model = ee_ridge_linear_regression(delta, \n",
    "                                         X=Z, y=y, penalty=0.5)\n",
    "    y_model = np.nan_to_num(y_model, copy=False, nan=0.)\n",
    "    ya1_hat = np.dot(Za, delta)\n",
    "    ya0_hat = np.dot(Zn, delta)\n",
    "\n",
    "    # Creating IPW\n",
    "    pi = np.where(A==1, pi_a*pi_m*pi_s, (1-pi_a)*pi_m*pi_s)\n",
    "    \n",
    "    # Calculating ACE\n",
    "    y1_star = np.where(ds['Y'].isna(), ya1_hat, (y*A/pi - ya1_hat*(A-pi)/pi)) - theta[1]\n",
    "    y0_star = np.where(ds['Y'].isna(), ya0_hat, (y*(1-A)/pi - ya0_hat*(A-pi)/pi)) - theta[2]\n",
    "    ace = np.ones(y.shape[0]) * (theta[1] - theta[2]) - theta[0]\n",
    "\n",
    "    return np.vstack((ace,\n",
    "                      y1_star[None, :],\n",
    "                      y0_star[None, :],\n",
    "                      a_model,\n",
    "                      m_model,\n",
    "                      s_model, \n",
    "                      y_model))\n",
    "\n",
    "\n",
    "# dealing with confounding, missing, selection, efficiency ...\n",
    "starting_vals = list(estr3.theta) + [25, ] + [0, ]*12\n",
    "estr4 = MEstimator(psi_aipw, init=starting_vals)\n",
    "estr4.estimate(solver='lm')\n",
    "\n",
    "aipw_ace = estr4.theta[0]\n",
    "aipw_var = estr4.variance[0, 0]\n",
    "aipw_ci = estr4.confidence_intervals()[0, :]\n",
    "\n",
    "print(estr4.theta)\n",
    "print(\"======================================\")\n",
    "print(\"AIPW Estimator\")\n",
    "print(\"======================================\")\n",
    "print(\"ACE:   \", np.round(aipw_ace, 3))\n",
    "print(\"95% CI:\", np.round(aipw_ci, 3))\n",
    "print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae440a0",
   "metadata": {},
   "source": [
    "Let's visually compare our estimates over the build-up of our estimating equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ed35ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([naive_ace, cnfdr_ace, mssng_ace, slctn_ace, aipw_ace],\n",
    "            [0, 1, 2, 3, 4], \n",
    "            s=100, marker='o', c='k')\n",
    "plt.hlines([0, 1, 2, 3, 4], \n",
    "           [naive_ci[0], cnfdr_ci[0], mssng_ci[0], slctn_ci[0], aipw_ci[0]],\n",
    "           [naive_ci[1], cnfdr_ci[1], mssng_ci[1], slctn_ci[1], aipw_ci[1]], \n",
    "           colors='k')\n",
    "plt.yticks([0, 1, 2, 3, 4],\n",
    "           [\"Naive\", \"v1\", \"v2\", \"v3\", \"v4\"])\n",
    "plt.ylim([4.2, -0.2])\n",
    "# plt.xlim([0.25, 1.1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b044d9",
   "metadata": {},
   "source": [
    "Therefore, we can easily see how both the estimate and the uncertainty change as we address for the various sources of bias. Additionally, we can see a benefit of the AIPW estimator in terms of efficiency. Here, the AIPW estimator was simple, other more efficient options (and additional levels of robustness) may be possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
